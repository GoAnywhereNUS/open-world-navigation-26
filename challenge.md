---
layout: page
title: Navitrace Challenge
permalink: /challenge/
---

<img src="../assets/img/navitrace.png" alt="Alt text" style="display: block; margin: auto;">
<br>

Together with the [Navitrace benchmark](https://leggedrobotics.github.io/navitrace_webpage/), we present a challenge for Vision-Language Models (VLMs) in robot navigation. Given the promise and increasing focus on VLMs in robotics, we seek to provide a benchmark to compare VLM-based approaches and to gauge progress in this field.

We invite submissions applying VLMs or Vision-Language-Action models (VLAs) to our publicly hosted [leaderboard](https://huggingface.co/spaces/leggedrobotics/navitrace_leaderboard). Submissions before the cutoff date (_TBC_) will be considered for the Navitrace Challenge prize, to be announced and given out at the workshop.

üèÜ **Challenge Winner Award**: _TBC_